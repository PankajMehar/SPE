#encoding=utf-8
'''
Main file of MPE
'''

import ConfigParser
import string, os, sys
import attentionBatch
import modelProcessAndAssess
import gc
import time
import subprocess

if __name__=='__main__':
    
    # read config file
    cf = ConfigParser.SafeConfigParser()
    cf.read("pythonParamsConfig")
    
    main_dir=cf.get("param", "root_dir") # main work dir
    dataset_name=cf.get("param", "dataset_name") # the name of one dataset
    suffix=cf.get("param", "suffix") # the suffix of dataset, such as 10,100,1000
    class_name=cf.get("param", "class_name") # the relation name of data
    index=cf.get("param", "index") # the index of the dataset file
    
    trainingDataFile=os.path.join(main_dir+'/',dataset_name+'.splits','train.'+suffix,'train_'+class_name+'_'+index) # the full path of training data file. This path will be generated by main_dir, dataset_name, suffix, class_name and index.
    metagraphEmbeddings_path=cf.get("param", "metagraphEmbeddings_path") # the file path of metagraph embeddings
    wordsEmbeddings_data=None # words embeddings
    wordsEmbeddings_path=cf.get("param", "wordsEmbeddings_path") # the file path of words embeddings

    wordsSize=cf.getint("param", "wordsSize") # the size of words vocabulary
    subpaths_map=None # contains sub-paths
    subpaths_file=cf.get("param", "subpaths_file") # the file which contains sub-paths
    maxlen_subpaths=cf.getint("param", "maxlen_subpaths") # the max length for sub-paths
    maxlen=cf.getint("param", "maxlen")  # Sequence longer then this get ignored 
    batch_size=cf.getint("param", "batch_size") # use a batch for training. This is the size of this batch.
    is_shuffle_for_batch=cf.getboolean("param", "is_shuffle_for_batch") # if need shuffle for training
    objective_function_method=cf.get("param", "objective_function_method")  # loss function, we use sigmoid here
    objective_function_param=cf.getfloat("param", "objective_function_param") # the parameter in loss function, beta
    lrate=cf.getfloat("param", "lrate") # learning rate
    max_epochs=cf.getint("param", "max_epochs") # the max epochs for training
    
    dispFreq=cf.getint("param", "dispFreq") # the frequences for display
    saveFreq=cf.getint("param", "saveFreq") # the frequences for saving the parameters
    saveto=os.path.join(main_dir+'/',dataset_name+'.trainModels','train.'+suffix,'train_'+class_name+'_'+index+'.npz') # the path for saving parameters. It is generated by main_dir, dataset_name, suffix, class_name and index.
    
    metagraph_embedding_dimension=cf.getint("param", "metagraph_embedding_dimension") # metagraph embedding dimension 
    dimension_A=cf.getint("param", "dimension_A") # the dimension of attention when computing the m-node embedding
    dimension_lstm=cf.getint("param", "dimension_lstm") # dimension of lstm parameters
    dimension_B=cf.getint("param", "dimension_B") # the dimension of attention when computing the m-path embedding
    dimension_C=cf.getint("param", "dimension_C") # the dimension of attention when computing the m-paths embedding
    
    # decay parameters
    decay_Q_A=cf.getfloat("param", "decay_Q_A") 
    decay_b_A=cf.getfloat("param", "decay_b_A") 
    decay_eta_A=cf.getfloat("param", "decay_eta_A") 
    
    decay_lstm_W=cf.getfloat("param", "decay_lstm_W") 
    decay_lstm_U=cf.getfloat("param", "decay_lstm_U") 
    decay_lstm_b=cf.getfloat("param", "decay_lstm_b") 
    decay_w=cf.getfloat("param", "decay_w") 
    
    decay_Q_B=cf.getfloat("param", "decay_Q_B") 
    decay_b_B=cf.getfloat("param", "decay_b_B") 
    decay_eta_B=cf.getfloat("param", "decay_eta_B") 
    
    decay_Q_C=cf.getfloat("param", "decay_Q_C") 
    decay_b_C=cf.getfloat("param", "decay_b_C") 
    decay_eta_C=cf.getfloat("param", "decay_eta_C") 
    
    # test and ideal data
    test_data_file=os.path.join(main_dir+'/',dataset_name+'.splits','test','test_'+class_name+'_'+index) # test data file
    top_num=cf.getint("param", "top_num") # top num in experiments
    ideal_data_file=os.path.join(main_dir+'/',dataset_name+'.splits','ideal','ideal_'+class_name+'_'+index) # ideal data file
    
    # training
    attentionBatch.metagraphAttentionTraining(
                    trainingDataFile, 
                    metagraphEmbeddings_path, 
                    wordsEmbeddings_data, 
                    wordsEmbeddings_path, 
                    wordsSize, 
                    subpaths_map, 
                    subpaths_file, 
                    maxlen_subpaths, 
                    maxlen, 
                    batch_size, 
                    is_shuffle_for_batch, 
                    objective_function_method, 
                    objective_function_param, 
                    lrate, 
                    max_epochs, 
                    dispFreq, 
                    saveFreq, 
                    saveto, 
                    metagraph_embedding_dimension, 
                    dimension_A, 
                    dimension_lstm, 
                    dimension_B, 
                    dimension_C, 
                    decay_Q_A,
                    decay_b_A,
                    decay_eta_A,
                    decay_lstm_W, 
                    decay_lstm_U, 
                    decay_lstm_b, 
                    decay_Q_B,
                    decay_b_B,
                    decay_eta_B,
                    decay_Q_C,
                    decay_b_C,
                    decay_eta_C,
                    decay_w)
    
    time.sleep(5) # sleep
    
#     child = subprocess.Popen("nohup python experimentForOneFileByParams_second.py &",shell=True)
    
    start_time = time.time() 
    print 'This time ==',time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(start_time))
    a=gc.collect()
    print 'First time to release number of objects from RAM ==', a
    b=gc.collect()
    print 'Second time to release number of objects from RAM ==', b
    c=gc.collect()
    print 'Third time to release number of objects from RAM ==', c
     
    # get the process model
    func=modelProcessAndAssess.get_metagraphAttentionModel(
                    saveto, 
                    metagraph_embedding_dimension, 
                    dimension_A, 
                    dimension_lstm, 
                    dimension_B, 
                    dimension_C)
     
    # gc
    gc.collect()
    gc.collect()
    gc.collect()
     
    # test and get the results
    MAP,MnDCG=modelProcessAndAssess.compute_metagraphAttention(
                    wordsEmbeddings_data, 
                    wordsEmbeddings_path, 
                    metagraphEmbeddings_path, 
                    wordsSize, 
                    subpaths_map, 
                    subpaths_file, 
                    maxlen_subpaths, 
                    test_data_file, 
                    top_num, 
                    ideal_data_file, 
                    func)
     
    print '......'
    end_time = time.time() 
    print 'Final time ==',time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(end_time))
    print 'MAP =', MAP
    print 'NDCG =', MnDCG